# HuaWei-Code-Craft-2018 软件精英挑战赛
欢迎在issues界面交流技术问题
## 1. 方案
* 文件中包含三部分内容:①数据前处理与特征工程②机器学习预测部分③装箱问题/背包问题
### 1.1 数据前处理与特征工程
* ①首先对缺失的日期补上零，因为缺失的日期表示当日所有的虚拟机类型都没有请求<br>
* ②提取特征，都说特征决定了模型性能的上限，而算法只能无限逼近你的上限，每天100次提交机会，你可以尝试各种各样的特征。我其实也很想知道排名靠前的人特征是怎么选的.对于我选用的树模型，可以输出特征重要度，可问题是我们根本拿不到训练集，所以也不知道测试用例的训练集上哪个特征比较重要，此外将练习数据表现良好的特征，用到测试用例上，得分并不像理想中的那么高，个人看来特征还是比较依赖训练集，而不是通用的，如果能拿到训练集，我们就可以同样用网格搜索来选取一组优秀的特征<br>
**思考** ：①特征的选择是否依赖与训练集？②最好的那组特征是否依赖于算法？至少看起来不同的算法之间的最优特征是不一样的吧！
### 1.2 机器学习预测部分
初步选取了特征之后，就要给定模型了。本次比赛有很多模型可供选择：基于树的模型，逻辑回归模型，循环神经网络，以及计量经济学方面的时间序列分析模型：ARIMA
每个模型有其各自的优势和不足，只要参数调的好，都能有不错的表现，希望下次能尝试不同的模型。
* **模型**：本次比赛使用的是GBDT单模型：gradient boosting decistion tree ,是由CART(classification and regression tree分类回归树)集成得到的
* **超参调试**: 对于机器学习而言，除了模型中要求解的参数之外，比如神经网络的权重，树模型的分裂点，逻辑回归的系数，还需要对其他参数进行配置，这些超参数（hyperparameter）设置的好坏，将直接影响模型的性能。比赛中包含的超参数主要有：<br>
`--树的深度`：树越深，学习能力越强，要防止过拟合<br>
`--树中节点的数目`：节点越少，学习能力越强，如果每个节点都只有一个样本，那就100%的学习了样本，当然肯定严重过拟合了<br>
`--树的数目`：树越多，学习能力越强<br>
当然还有很多其他参数，但是这三个参数对于得分的影响是最为显著的。不同的模型，要理解其每个参数的变化对于模型性能的影响，以最大化模型的泛化能力。交叉验证在一定程度上有助于你选择一组泛化较佳的参数。
* **模型融合**：对于机器学习任务而言，单模型往往不够用，或者说采用多个模型融合，性能更好，常用的模型融合方法有：<br>
`--averaging/voting`:averaging用于回归，voting用于分类，这要求各个模型表现的都差不多，而且都不差<br>
`--stacking`:这要求各个模型对数据集有各自的优势，比如模型A对某种类型的样本预测效果好，模型B对另一中类型的预测效果好，则可以用stacking方法，把两个模型的融合到一起，使得融合后的模型即拥有模型A的优势，也有模型B的优势。
### 1.3 装箱问题
装箱问题有很多类型，这次比赛的类型是属于二维的装箱问题，箱子的尺寸都一样，算法有很多也很成熟，没什么好说的。



